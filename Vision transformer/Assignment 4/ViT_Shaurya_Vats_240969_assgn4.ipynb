{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-woU4Sodh6ND"
      },
      "cell_type": "markdown",
      "source": [
        "# Assignment #4\n",
        "\n",
        "\n",
        "Vision Transformer\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "UMQvV4nljttN"
      },
      "cell_type": "markdown",
      "source": [
        "# 1. Batch Normalization"
      ]
    },
    {
      "metadata": {
        "id": "JT_kxpjbNQUr"
      },
      "cell_type": "markdown",
      "source": [
        "Training a deep neural network is a tricky process. Many techniques have already been proposed for more stable training and faster convergence. Most of these techniques either change the model architecture or improve the training algorithm. Batch normalization belongs to the former group. The method was introduced in 2015 and achieved state-of-the-art in ImageNet,  a well-known image classification benchmark."
      ]
    },
    {
      "metadata": {
        "id": "vDcK52jRj_mD"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.1 Definition"
      ]
    },
    {
      "metadata": {
        "id": "owKLAOJVj73I"
      },
      "cell_type": "markdown",
      "source": [
        "We generally normalize the inputs of a neural network to speed up the convergence. So if the \"normalization\" works, why not try it on the activation values? How can we improve training by normalizing the values of intermediate layers?\n",
        "\n",
        "Here is an intermediate layer $l$ in some neural network:\n",
        "\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/01_intermediate_layer.jpg\" width=\"500\"/></p>\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "nKOwOymYSVK8"
      },
      "cell_type": "markdown",
      "source": [
        "The general idea is to train layer $l$ faster by normalizing its input. By the layer $l$ we simply mean weigth matrices $W^{l}$, $b^{l}$ and by the input we mean previous layer's activations $a^{l-1}$. For the sake of simplicity, let us change our notation. Instead of normalizing the input of layer $l$, we would like to normalize the output so that the next layers will receive normalized values from our layer. It has the same effect, but it will make the equations much cleaner.\n",
        "\n",
        "In practice, we do not normalize the output (the activations). Instead, we do the normalization on the weighted sum of inputs $Z^{l}$ just before applying the activation function ($Z^l = xW^l+b^l$).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "D_xmxSzHkqrT"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.2 The formula"
      ]
    },
    {
      "metadata": {
        "id": "PjFpIC3HgxrO"
      },
      "cell_type": "markdown",
      "source": [
        "Assume we want some variable $x$ to have normalized values, the only way to do that is to collect all of its values and calculate the mean and variance in order to create a normalized version of $x$. This is a fairly reasonable solution, and we use it to normalize the neural network's input. Now imagine the goal is to normalize some intermediate values in a deep neural network; Collecting values of some intermediate point in a neural network is almost impossible since the training algorithm can change them entirely. To overcome this issue, we can collect them over a mini-batch.  It will give us an estimated version of the mean and variance. This is why it is called Batch Normalization. Here is the detailed algorithm:\n",
        "\n",
        "Given values of $x$ over a mini-batch $\\mathcal{B} = \\{x_1, .., x_m\\}$ :\n",
        "\n",
        "$$\n",
        "\\mu _\\mathcal{B} = \\frac{1}{m} \\sum^{m}_{i=1} x_i  \\ \\ \\ \\ \\ \\text{(mini-batch mean)}\n",
        "\\\\\n",
        "\\sigma^2 _\\mathcal{B} = \\frac{1}{m} \\sum^{m}_{i=1} (x_i-\\mu _\\mathcal{B})\n",
        "\\ \\ \\ \\ \\ \\text{(mini-batch variance)}\n",
        "\\\\\n",
        "x^{norm}_i = \\frac{x_i - \\mu _\\mathcal{B}}{\\sqrt{\\sigma^2 _\\mathcal{B} + \\epsilon}} \\ \\ \\ \\ \\ \\text{(normalize)}\n",
        "\\\\\n",
        "\\hat{x}_i =\\gamma x^{norm}_i+\\beta  \\ \\ \\ \\ \\ \\text{(scale and shift)}\n",
        "\\\\\n",
        "\\mathrm{BN(\\mathcal{B}, \\gamma, \\beta}) = \\{\\hat{x}_1, ..., \\hat{x}_m\\}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "72SOE7UfxmEh"
      },
      "cell_type": "markdown",
      "source": [
        "**Notes:**\n",
        "1. All of the notations above are non-vector.\n",
        "2. $\\gamma$ and $\\beta$ are learnable parameters.\n",
        "3. $\\epsilon$ is just a small number, and we use it for numerical stability.\n",
        "4. $\\mathrm{BN}$ function calculates its output based on a batch of values. Consequently, we'll have different $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ for each mini-batch during the training process. We will reference this property in the next sections.\n",
        "5. $x^{norm}_i$ is actually the normalized version of $x_i$ which has mean 0 and variance 1. However, hidden units in neural networks have different distributions, and we don't really want them to all have the same distribution, So instead, we just scale and shift $x^{norm}_i$ with two variables $\\gamma$, $\\beta$.\n",
        "6. Another reason for the extra \"scale & shift\" step is that if we choose $\\gamma = \\sqrt{\\sigma^2_\\mathcal{B} + \\epsilon}$ and $\\beta = \\mu_\\mathcal{B}$ then $\\hat{x}_i$ will become $x_i$, So the optimizer can easily remove the batch normalization if it is sufficient for proper training.\n",
        "\n",
        "One difference between normalizing a neural network's inputs and Batch Normalization is that the latter does not force values to have mean 0 and variance 1."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Explain it with at least one reason, why we might not want the hidden units to be forced to have mean 0 and variance 1.**"
      ],
      "metadata": {
        "id": "McQ7-6VxRS3I"
      }
    },
    {
      "metadata": {
        "id": "rrTaUoPMLhyl"
      },
      "cell_type": "markdown",
      "source": [
        "If hidden units were always forced to have mean 0 and variance 1, the network would lose flexibility. Different layers may naturally need different ranges of values, and fixing every layer to exactly the same mean and variance can limit what the model is able to learn. Batch normalization first normalizes values to mean 0 and variance 1, but then introduces two learnable parameters, gamma and beta. Gamma controls the scale and beta controls the shift. Because of these parameters, the network is free to move away from mean 0 and variance 1 whenever that helps performance, instead of being strictly forced to keep those values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Where is Batch Normalization generally applied relative to the activations.**"
      ],
      "metadata": {
        "id": "R2f1WO9jSWS_"
      }
    },
    {
      "metadata": {
        "id": "gLEtRi9hSrxC"
      },
      "cell_type": "markdown",
      "source": [
        "Batch normalization is usually applied before the activation function in a layer. The common order is:\n",
        "\n",
        "linear transformation (weights and bias) → batch normalization → activation function\n",
        "\n",
        "So the normalization is done on the pre-activation values, not on the final activations.\n"
      ]
    },
    {
      "metadata": {
        "id": "8few4PaaXf9t"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2.2 Batch normalization at test time\n",
        "\n",
        "As we said, We will have multiple $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ since they are calculated individually for each mini-batch. So What should we do for the test time? In fact, the idea is quite simple; We can just calculate a moving average of $\\mu_\\mathcal{B}$ and $\\sigma^2_\\mathcal{B}$ to use at test time. Deep learning frameworks such as Tensorflow are using this algorithm in their default bach normalization implementations."
      ]
    },
    {
      "metadata": {
        "id": "wwyIr1ChkvzY"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.3 Applying the batch-norm on layers"
      ]
    },
    {
      "metadata": {
        "id": "Wu85xhmM1xFv"
      },
      "cell_type": "markdown",
      "source": [
        "Batch Normalization (or simply batch-norm) doesn't know anything about the concept of layers and vectors. we have to integrate it manually in our layers. For a given d-dimensional vector of logits $Z = (z^{(1)},..., z^{(d)})$, the batch-normalized version is\n",
        "\n",
        "$$\n",
        "Z = (\\ \\mathrm{BN}(\\mathcal{B}\\{z^{(1)}\\}, \\gamma^{(1)}, \\beta^{(1)}),..., \\mathrm{BN}(\\mathcal{B}\\{z^{(d)}\\}, \\gamma^{(d)}, \\beta^{(d)})\\ )\n",
        "$$\n",
        "\n",
        "As you might have noticed, we need a batch for each $Z$'s element in the latter version. In other words, we need a batch of $Z$. Fortunately, this is good news for us since we build our neural networks entirely based on batches.\n",
        "\n",
        "Write the vectorized version of batch-norm equations and specify the dimensions.\n",
        "\n",
        "For any given layer $l$ with $n$ hidden units and batch size $b$:\n",
        "\n",
        "$$\n",
        "z = xW + B\\ \\ \\ \\  z \\in \\mathbb{R} ^ {b \\times n}, W \\in \\mathbb{R} ^ {m \\times n}, B \\in \\mathbb{R} ^ {b \\times n}, x \\in \\mathbb{R} ^ {b \\times m}\n",
        "$$\n"
      ]
    },
    {
      "metadata": {
        "id": "A-J18TTk_Uh1"
      },
      "cell_type": "markdown",
      "source": [
        "**3.**\n",
        "$$\n",
        "\\mu = (1⁄b )∑ᵢ₌₁ᵇ zᵢ\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sigma^2 = (1⁄b) ∑ᵢ₌₁ᵇ (zᵢ − μ)²\n",
        "$$\n",
        "\n",
        "$$\n",
        "z^{norm} = (z − μ) / √(σ² + ε)\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\hat{z} = \\gamma \\odot z^{norm} + \\beta  \\ \\ \\ \\ \\ \\ (\\odot \\text{ is an element-wise dot product} )\n",
        "$$"
      ]
    },
    {
      "metadata": {
        "id": "UmrjugAKYs0p"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine a simple neural network with l hidden layers. We want to apply the batch-norm on all layers. Here is how it would look ($\\mathcal{X}^{b} $ is an input batch):\n",
        "\n",
        "$$\n",
        "\\mathcal{X}^{b}\\stackrel{W^{[1]}, B^{[1]}}{\\longrightarrow}Z^{[1]} \\stackrel{\\gamma^{[1]}, \\beta^{[1]}}{\\longrightarrow}\\hat{Z}^{[1]} \\longrightarrow a^{[1]} = func^{[1]}(\\hat{Z}^{[1]})\\stackrel{W^{[2]}, B^{[2]}}{\\longrightarrow} ...\n",
        "$$\n",
        "\n",
        "Also, the parameters for that neural network would be:\n",
        "$$\n",
        "W^{[1]}, B^{[1]} \\ \\  \\ \\ W^{[2]}, B^{[2]}  \\ \\ ... \\ \\ W^{[l]}, B^{[l]}\n",
        "\\\\\n",
        "\\gamma^{[1]}, \\beta^{[1]} \\ \\ \\ \\  \\  \\ \\ \\gamma^{[2]}, \\beta^{[2]}  \\ \\ \\ \\  ... \\ \\ \\ \\ \\gamma^{[l]}, \\beta^{[l]}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. $B^{[i]}$ is the bias term in our neural network, but with incorporating the batch-norm and introduction of new variables,Do you think $B^{[i]}$ is necessary? Justify your answer with proper reasons.**"
      ],
      "metadata": {
        "id": "sTKOPL1rU3xt"
      }
    },
    {
      "metadata": {
        "id": "Tqv6BuLfirk8"
      },
      "cell_type": "markdown",
      "source": [
        "The bias term B[i] becomes unnecessary once batch normalization is used. The reason is that batch normalization already includes two learnable parameters, gamma and beta. Beta acts as a shift term, which plays the same role as the bias. During normalization, the mean is removed from the activations, so any fixed bias would be canceled out anyway. Then beta reintroduces a learnable shift. Because of this, keeping B[i] does not add extra expressive power and mainly becomes redundant, so in practice it is usually omitted when batch normalization is applied.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "T0PrEPOdlE9d"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.4 Why does it work?"
      ]
    },
    {
      "metadata": {
        "id": "AVqGS4J6lJlf"
      },
      "cell_type": "markdown",
      "source": [
        "Imagine a super simple neural network:\n",
        "\n",
        "<br/>\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/02_simple_nn.png\" width=\"300\"/>\n",
        "<br>\n",
        "  [[source](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)]\n",
        "</p>\n",
        "\n",
        "</br>\n",
        "During the training, Our optimizer calculates the gradients with respect to weights. Take layer **a** as an example; Optimizer calucates  $\\frac{\\partial L}{\\partial a}$ and then it updates the weights for this layer. Unfortunately,  it means that weight update for Layer **a** only depends on the sensitivity of loss function to that weight. However, changing weights of initial layers can completely effect the statistics of any futher layer.\n",
        "\n",
        "With the presence of Batch Normalization, our optimizer package can now adjust two parameters $\\gamma$, $\\beta$ to change statistics of any layer, rather than entire weight matrix. It makes the training of any layer independent and also introduces some checkpointing mechanism.\n",
        "\n",
        "Besides, recent findings show that batch normalization smoothes the landscape/surface of the loss function, effectively making the optimization performance less dependant on the initial state.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://iust-deep-learning.github.io/972/static_files/assignments/asg03_assets/03_error_surface.jpg\"  width=\"700\"/>\n",
        "<br/>\n",
        "  source: [2]\n",
        "  </p>"
      ]
    },
    {
      "metadata": {
        "id": "VZlJ4Hic2aoN"
      },
      "cell_type": "markdown",
      "source": [
        "## 1.5 Batch Normalization in action\n"
      ]
    },
    {
      "metadata": {
        "id": "cSqjUrD02hiL"
      },
      "cell_type": "markdown",
      "source": [
        "Now let's create a layer to use batch normalization easier."
      ]
    },
    {
      "metadata": {
        "id": "YwY8vwus2xQu"
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Layer, Dense, Activation, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Complete the following Class**"
      ],
      "metadata": {
        "id": "R6TKpXssrUqc"
      }
    },
    {
      "metadata": {
        "id": "Gt5mzXXX2s5V"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class BatchNormalizedLayer(Layer):\n",
        "    def __init__(self, layer, axis=-1, activation=None, **kwargs):\n",
        "        \"\"\"Runs batch normalization on layer instance and applies the activation function\n",
        "\n",
        "        Args:\n",
        "          layer(layers.Layer): A layer to normalize its output\n",
        "          axis(int): the axis that should be normalized (typically the features axis).\n",
        "          activation(str): Activation function to use\n",
        "        \"\"\"\n",
        "        super(BatchNormalizedLayer, self).__init__(**kwargs)\n",
        "\n",
        "        self.layer = layer\n",
        "        self.activation = activation\n",
        "        self.axis = axis\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Runs the layer\n",
        "\n",
        "        Args:\n",
        "          inputs: The layer's input\n",
        "        \"\"\"\n",
        "        x = self.layer(inputs)\n",
        "        x = layers.BatchNormalization(axis=self.axis)(x)\n",
        "\n",
        "        if self.activation is not None:\n",
        "            x = layers.Activation(self.activation)(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cc0wyxlb7JwJ"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf # Import tensorflow\n",
        "\n",
        "bnl = BatchNormalizedLayer(Dense(5), activation='relu')\n",
        "x = tf.constant(2.5 * np.random.randn(10, 4) + 3, dtype=tf.float32) # Use tf.constant\n",
        "\n",
        "# Evaluate the output using tf.keras.backend.get_value\n",
        "assert tf.keras.backend.get_value(bnl(x)).shape == (10, 5)\n",
        "#this is just a check to see if the Layer is working as expected ,it doesnot print anything"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "id": "E-Tlpqm-_dyH"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.5.1 CNN"
      ]
    },
    {
      "metadata": {
        "id": "ZPLoHHW1_qdv"
      },
      "cell_type": "markdown",
      "source": [
        "Now we have our special layer. So, let's use it in a real neural network. We want to improve the baseline using the Batch Normalization layer. Our desired task is CIFAR10 image  classification.\n",
        "\n",
        "First, let's load the dataset:"
      ]
    },
    {
      "metadata": {
        "id": "wm79YEyIAmKa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "36af5e28-a5ab-41ac-c70e-338a442c11d5"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# 6.Convert class vectors to binary class matrices.\n",
        "y_train = to_categorical(y_train, num_classes)\n",
        "y_test = to_categorical(y_test, num_classes)\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# Visualizing CIFAR 10\n",
        "fig, axes1 = plt.subplots(2,5,figsize=(10,4))\n",
        "for j in range(2):\n",
        "  for k in range(5):\n",
        "    i = np.random.choice(range(len(x_train)))\n",
        "    axes1[j][k].set_axis_off()\n",
        "    axes1[j][k].imshow(x_train[i:i+1][0])\n",
        "\n",
        "# Normalize\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "UBb__seXIyRN"
      },
      "cell_type": "code",
      "source": [
        "def visualize_loss_and_acc(history):\n",
        "  history_dict = history.history\n",
        "  loss_values = history_dict['loss']\n",
        "  val_loss_values = history_dict['val_loss']\n",
        "  acc = history_dict['acc']\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  f = plt.figure(figsize=(10,3))\n",
        "\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "  plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "  plt.title('Training and validation loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "\n",
        "  acc_values = history_dict['acc']\n",
        "  val_acc = history_dict['val_acc']\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qlKS6lsIzLX"
      },
      "cell_type": "markdown",
      "source": [
        "#### Baseline"
      ]
    },
    {
      "metadata": {
        "id": "CzzXJ2M6GXn-"
      },
      "cell_type": "markdown",
      "source": [
        "Define the baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![CNN Architecture](https://drive.google.com/uc?id=1Fh3Z94KKHe9sAzUorZlW9NXMPN6NAhlx\n",
        ")\n"
      ],
      "metadata": {
        "id": "2fLyt7WKl8F-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The figure above shows the architecture of a **baseline Convolutional Neural Network (CNN)** used for multi-class image classification.\n",
        "\n",
        "The architecture consists of the following components in **Sequential order**:\n",
        "\n",
        "- Convolutional layers with **3×3 kernels** and **padding = 'same'**\n",
        "- ReLU activation after each convolution\n",
        "- MaxPooling layers with **2×2 pool size**\n",
        "- Dropout layers for regularization\n",
        "- A fully connected Dense layer\n",
        "- A Softmax output layer\n",
        "\n",
        "**7.** Based on the **architecture shown in the image** and the details mentioned above, implement the CNN model in Keras by completing the function below.\n",
        "\n",
        "- Ensure that the **number of layers, order of layers, kernel sizes, pooling sizes, dropout rates, padding, and activations** exactly match the given architecture\n",
        "- Do **not** change the function name or signature\n"
      ],
      "metadata": {
        "id": "eFWdmvXlnWNN"
      }
    },
    {
      "metadata": {
        "id": "ZnXcRHpuDcvS"
      },
      "cell_type": "code",
      "source": [
        "def get_baseline_model():\n",
        "  model = Sequential()\n",
        "\n",
        "  ## HINT : input_shape=x_train.shape[1:]\n",
        "\n",
        "    ########################################\n",
        "    #     Put your implementation here     #\n",
        "    ########################################\n",
        "\n",
        "  model = Sequential([\n",
        "\n",
        "    Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]),\n",
        "    Activation('relu'),\n",
        "    Conv2D(32, (3, 3), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    Activation('relu'),\n",
        "    Conv2D(64, (3, 3), padding='same'),\n",
        "    Activation('relu'),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512),\n",
        "    Activation('relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes),\n",
        "    Activation('softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TQ2uoSmGlvP"
      },
      "cell_type": "markdown",
      "source": [
        "Train the baseline"
      ]
    },
    {
      "metadata": {
        "id": "2Q45b4cVF36l"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 25"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "id": "488nX4FSDzs-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "outputId": "42cc2e7d-4803-4943-8651-6da8bae3cbb6"
      },
      "cell_type": "code",
      "source": [
        "# Create the baseline model\n",
        "baseline = get_baseline_model()\n",
        "\n",
        "# Train model\n",
        "bs_history = baseline.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 204ms/step - accuracy: 0.2815 - loss: 1.9528 - val_accuracy: 0.4627 - val_loss: 1.4889\n",
            "Epoch 2/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 203ms/step - accuracy: 0.4571 - loss: 1.4935 - val_accuracy: 0.5388 - val_loss: 1.3040\n",
            "Epoch 3/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 207ms/step - accuracy: 0.5260 - loss: 1.3263 - val_accuracy: 0.5782 - val_loss: 1.1908\n",
            "Epoch 4/25\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 202ms/step - accuracy: 0.5675 - loss: 1.2135 - val_accuracy: 0.6198 - val_loss: 1.0881\n",
            "Epoch 5/25\n",
            "\u001b[1m 557/1563\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m3:21\u001b[0m 200ms/step - accuracy: 0.5947 - loss: 1.1403"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1030187800.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m bs_history = baseline.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1687\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1688\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1689\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "AJgQ9yxpGp8P"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the training and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "VeVuiJmHGUw7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "76206e9d-207e-411b-e2ee-cf775cf612d0"
      },
      "cell_type": "code",
      "source": [
        "visualize_loss_and_acc(bs_history)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'bs_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4194250235.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_loss_and_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'bs_history' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "8aMc7UWPICG9"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = baseline.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufqdGaLrI4oZ"
      },
      "cell_type": "markdown",
      "source": [
        "#### Improved"
      ]
    },
    {
      "metadata": {
        "id": "dm8Yu20HHBXp"
      },
      "cell_type": "markdown",
      "source": [
        "**8. Now update the baseline to create an enhanced model only by using `BatchNormalizedLayer`**"
      ]
    },
    {
      "metadata": {
        "id": "aD6NqqZ3Hbeg"
      },
      "cell_type": "code",
      "source": [
        "def get_improved_model():\n",
        "\n",
        "  model = Sequential()\n",
        "\n",
        "  ########################################\n",
        "  #     Put your implementation here     #\n",
        "  ########################################\n",
        "  ## remember you have to use your baseline and add batch normalized layers using the previous Model\n",
        "  model.add(BatchNormalizedLayer(Conv2D(32, (3, 3), padding='same', use_bias=False), activation='relu', input_shape=x_train.shape[1:]))\n",
        "  model.add(BatchNormalizedLayer(Conv2D(32, (3, 3), padding='same', use_bias=False), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "    # Block 2: 64 Filters with Batch Normalization\n",
        "  model.add(BatchNormalizedLayer(Conv2D(64, (3, 3), padding='same', use_bias=False),  activation='relu'))\n",
        "  model.add(BatchNormalizedLayer(Conv2D(64, (3, 3), padding='same', use_bias=False),  activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Dropout(0.25))\n",
        "\n",
        "    # Block 3: Fully Connected with Batch Normalization\n",
        "  model.add(Flatten())\n",
        "  model.add(BatchNormalizedLayer(Dense(512, use_bias=False), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "\n",
        "    # Output Layer\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer=keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oYmlozp3I8Ts"
      },
      "cell_type": "markdown",
      "source": [
        "Train and evaluate"
      ]
    },
    {
      "metadata": {
        "id": "mLNW4dnsH9NF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "collapsed": true,
        "outputId": "0a449f67-88b1-4406-d456-dd11d8ebbb81"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# Create the baseline model\n",
        "impv_model = get_improved_model()\n",
        "\n",
        "# Train model\n",
        "impv_history = impv_model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-168481720.py:13: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super(BatchNormalizedLayer, self).__init__(**kwargs)\n",
            "Exception ignored in: <function _xla_gc_callback at 0x7a02febce5c0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/jax/_src/lib/__init__.py\", line 127, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2647771492.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m impv_history = impv_model.fit(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    373\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcontextlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/keras/src/trainers/epoch_iterator.py\u001b[0m in \u001b[0;36m_enumerate_iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_epoch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_seen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m       raise RuntimeError(\"`tf.data.Dataset` only supports Python-style \"\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    707\u001b[0m             \u001b[0;34m\"When `dataset` is provided, `element_spec` and `components` must \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m             \"not be specified.\")\n\u001b[0;32m--> 709\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_next_call_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    746\u001b[0m             self._flat_output_types)\n\u001b[1;32m    747\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_set_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfulltype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   3476\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3477\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3478\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   3479\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   3480\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Fsz97z1Q-eoA"
      },
      "cell_type": "markdown",
      "source": [
        "Visualize the training and evaluate the model"
      ]
    },
    {
      "metadata": {
        "id": "30JMMBQyIb49"
      },
      "cell_type": "code",
      "source": [
        "visualize_loss_and_acc(impv_history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZoqlKrUAIb4_"
      },
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = impv_model.evaluate(x_test, y_test, verbose=1)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L-vfDkCCycqZ"
      },
      "cell_type": "markdown",
      "source": [
        "**Question:** Compare your model to the baseline. What are the diffrences? Does batch normalization work?"
      ]
    },
    {
      "metadata": {
        "id": "VjOOqiDDyf4p"
      },
      "cell_type": "markdown",
      "source": [
        "Yes, batch normalization works.\n",
        "\n",
        "Faster Convergence: Batch Normalization enables the network to use larger learning rates, leading to quicker training as the optimization surface becomes smoother.\n",
        "\n",
        "Stability: The training process becomes less sensitive to the initial weight values.\n",
        "\n",
        "Regularization Effect: BN introduces a small amount of noise into the activations (calculated from mini-batch statistics), which often provides a slight regularization effect similar to Dropout.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oJLRl0DL5aSO"
      },
      "cell_type": "markdown",
      "source": [
        "# References\n"
      ]
    },
    {
      "metadata": {
        "id": "LCQPkvV83Kn0"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Ioffe, Sergey, and Christian Szegedy. “Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.” ArXiv:1502.03167 [Cs], February 10, 2015. http://arxiv.org/abs/1502.03167.\n",
        "* Im, Daniel Jiwoong, Michael Tao, and Kristin Branson. “An Empirical Analysis of the Optimization of Deep Network Loss Surfaces.” ArXiv:1612.04010 [Cs], December 12, 2016. http://arxiv.org/abs/1612.04010.\n",
        "* Santurkar, Shibani, Dimitris Tsipras, Andrew Ilyas, and Aleksander Madry. “How Does Batch Normalization Help Optimization?” In Advances in Neural Information Processing Systems 31, edited by S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Garnett, 2483–2493. Curran Associates, Inc., 2018. http://papers.nips.cc/paper/7515-how-does-batch-normalization-help-optimization.pdf.\n",
        "* Coursera Course: Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization\n",
        "* Intro to optimization in deep learning: Busting the myth about batch normalization [[link](https://blog.paperspace.com/busting-the-myths-about-batch-normalization/)]\n",
        "* Why Does Batch Normalization Work? [[link](https://abay.tech/blog/2018/07/01/why-does-batch-normalization-work/)]\n",
        "*  http://www.cs.toronto.edu/~tingwuwang/semantic_segmentation.pdf\n",
        "*  https://medium.com/nanonets/how-to-do-image-segmentation-using-deep-learning-c673cc5862ef\n",
        "* https://www.jeremyjordan.me/semantic-segmentation/\n",
        "\n"
      ]
    }
  ]
}